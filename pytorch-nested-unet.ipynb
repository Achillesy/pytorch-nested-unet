{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6811a08a-f9ab-4f5f-9108-ee41cc3ed8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "# gData = '/gdrive/MyDrive/Data'\n",
    "\n",
    "## Kaggle\n",
    "# gData = '/kaggle/input'\n",
    "\n",
    "## Mac mini (M1 2020)\n",
    "# gData = '/Users/achilles/Workspace/Data'\n",
    "\n",
    "## HP-Z4-G4 Ubuntu\n",
    "gData = \"/mnt/Storage/Xuchu_Liu/Workspace/Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a109c38d-194a-4a71-b649-ef2893296f75",
   "metadata": {},
   "source": [
    "## preprocess_dsb2018.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3debaeb-dcb7-4e05-b1d7-eb1b82b32d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31e8dfec-1e2c-41a5-8844-9e3dc5a2f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_size = 96\n",
    "\n",
    "# data_path = os.path.join(gData, 'data-science-bowl-2018')\n",
    "\n",
    "\n",
    "# paths = glob(os.path.join(data_path, 'stage1_train', '*'))\n",
    "\n",
    "# os.makedirs(os.path.join(data_path, 'dsb2018_%d/images' % img_size), exist_ok=True)\n",
    "# os.makedirs(os.path.join(data_path, 'dsb2018_%d/masks/0' % img_size), exist_ok=True)\n",
    "\n",
    "# for i in tqdm(range(len(paths))):\n",
    "#     path = paths[i]\n",
    "#     img = cv2.imread(os.path.join(path, 'images',\n",
    "#                      os.path.basename(path) + '.png'))\n",
    "#     mask = np.zeros((img.shape[0], img.shape[1]))\n",
    "#     for mask_path in glob(os.path.join(path, 'masks', '*')):\n",
    "#         mask_ = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) > 127\n",
    "#         mask[mask_] = 1\n",
    "#     if len(img.shape) == 2:\n",
    "#         img = np.tile(img[..., None], (1, 1, 3))\n",
    "#     if img.shape[2] == 4:\n",
    "#         img = img[..., :3]\n",
    "#     img = cv2.resize(img, (img_size, img_size))\n",
    "#     mask = cv2.resize(mask, (img_size, img_size))\n",
    "#     cv2.imwrite(os.path.join(data_path, 'dsb2018_%d/images' % img_size,\n",
    "#                 os.path.basename(path) + '.png'), img)\n",
    "#     cv2.imwrite(os.path.join(data_path, 'dsb2018_%d/masks/0' % img_size,\n",
    "#                 os.path.basename(path) + '.png'), (mask * 255).astype('uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96518a2-994a-41d0-9b30-131a3f0e0cdf",
   "metadata": {},
   "source": [
    "# train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e92d98b0-18cc-4795-acb6-e87fa2b0acc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import OrderedDict\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import yaml\n",
    "from albumentations.augmentations import transforms\n",
    "from albumentations.core.composition import Compose, OneOf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201ef2e2-44ab-4518-9382-641bc1682016",
   "metadata": {},
   "source": [
    "## archs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7901d144-7f76-4102-96da-ba67b7f43d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_channels, middle_channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(middle_channels)\n",
    "        self.conv2 = nn.Conv2d(middle_channels, out_channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "850ee635-d1bd-446f-9141-0a9e22b75bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vggblock = VGGBlock(1, 32, 32)\n",
    "# vggblock.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "811dca92-f40a-4cc8-a856-aabb3cda92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_classes, input_channels=3, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        nb_filter = [32, 64, 128, 256, 512]\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.conv0_0 = VGGBlock(input_channels, nb_filter[0], nb_filter[0])\n",
    "        self.conv1_0 = VGGBlock(nb_filter[0], nb_filter[1], nb_filter[1])\n",
    "        self.conv2_0 = VGGBlock(nb_filter[1], nb_filter[2], nb_filter[2])\n",
    "        self.conv3_0 = VGGBlock(nb_filter[2], nb_filter[3], nb_filter[3])\n",
    "        self.conv4_0 = VGGBlock(nb_filter[3], nb_filter[4], nb_filter[4])\n",
    "\n",
    "        self.conv3_1 = VGGBlock(nb_filter[3]+nb_filter[4], nb_filter[3], nb_filter[3])\n",
    "        self.conv2_2 = VGGBlock(nb_filter[2]+nb_filter[3], nb_filter[2], nb_filter[2])\n",
    "        self.conv1_3 = VGGBlock(nb_filter[1]+nb_filter[2], nb_filter[1], nb_filter[1])\n",
    "        self.conv0_4 = VGGBlock(nb_filter[0]+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "\n",
    "        self.final = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x0_0 = self.conv0_0(input)\n",
    "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
    "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
    "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
    "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
    "\n",
    "        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))\n",
    "        x2_2 = self.conv2_2(torch.cat([x2_0, self.up(x3_1)], 1))\n",
    "        x1_3 = self.conv1_3(torch.cat([x1_0, self.up(x2_2)], 1))\n",
    "        x0_4 = self.conv0_4(torch.cat([x0_0, self.up(x1_3)], 1))\n",
    "\n",
    "        output = self.final(x0_4)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "495f6153-7228-41ba-a6af-1765a21a7520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet = UNet(2,1)\n",
    "# unet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d9ef345-6d2e-4444-b571-ee0e30fa44a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestedUNet(nn.Module):\n",
    "    def __init__(self, num_classes, input_channels=3, deep_supervision=False, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        nb_filter = [32, 64, 128, 256, 512]\n",
    "\n",
    "        self.deep_supervision = deep_supervision\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.conv0_0 = VGGBlock(input_channels, nb_filter[0], nb_filter[0])\n",
    "        self.conv1_0 = VGGBlock(nb_filter[0], nb_filter[1], nb_filter[1])\n",
    "        self.conv2_0 = VGGBlock(nb_filter[1], nb_filter[2], nb_filter[2])\n",
    "        self.conv3_0 = VGGBlock(nb_filter[2], nb_filter[3], nb_filter[3])\n",
    "        self.conv4_0 = VGGBlock(nb_filter[3], nb_filter[4], nb_filter[4])\n",
    "\n",
    "        self.conv0_1 = VGGBlock(nb_filter[0]+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "        self.conv1_1 = VGGBlock(nb_filter[1]+nb_filter[2], nb_filter[1], nb_filter[1])\n",
    "        self.conv2_1 = VGGBlock(nb_filter[2]+nb_filter[3], nb_filter[2], nb_filter[2])\n",
    "        self.conv3_1 = VGGBlock(nb_filter[3]+nb_filter[4], nb_filter[3], nb_filter[3])\n",
    "\n",
    "        self.conv0_2 = VGGBlock(nb_filter[0]*2+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "        self.conv1_2 = VGGBlock(nb_filter[1]*2+nb_filter[2], nb_filter[1], nb_filter[1])\n",
    "        self.conv2_2 = VGGBlock(nb_filter[2]*2+nb_filter[3], nb_filter[2], nb_filter[2])\n",
    "\n",
    "        self.conv0_3 = VGGBlock(nb_filter[0]*3+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "        self.conv1_3 = VGGBlock(nb_filter[1]*3+nb_filter[2], nb_filter[1], nb_filter[1])\n",
    "\n",
    "        self.conv0_4 = VGGBlock(nb_filter[0]*4+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "\n",
    "        if self.deep_supervision:\n",
    "            self.final1 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "            self.final2 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "            self.final3 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "            self.final4 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "        else:\n",
    "            self.final = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x0_0 = self.conv0_0(input)\n",
    "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
    "        x0_1 = self.conv0_1(torch.cat([x0_0, self.up(x1_0)], 1))\n",
    "\n",
    "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
    "        x1_1 = self.conv1_1(torch.cat([x1_0, self.up(x2_0)], 1))\n",
    "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up(x1_1)], 1))\n",
    "\n",
    "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
    "        x2_1 = self.conv2_1(torch.cat([x2_0, self.up(x3_0)], 1))\n",
    "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up(x2_1)], 1))\n",
    "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.up(x1_2)], 1))\n",
    "\n",
    "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
    "        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))\n",
    "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up(x3_1)], 1))\n",
    "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], 1))\n",
    "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], 1))\n",
    "\n",
    "        if self.deep_supervision:\n",
    "            output1 = self.final1(x0_1)\n",
    "            output2 = self.final2(x0_2)\n",
    "            output3 = self.final3(x0_3)\n",
    "            output4 = self.final4(x0_4)\n",
    "            return [output1, output2, output3, output4]\n",
    "\n",
    "        else:\n",
    "            output = self.final(x0_4)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ec97d5c-5b1d-4d06-bfa3-be3c9ffd346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nestedunet = NestedUNet(2,1)\n",
    "# nestedunet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5dd77a-2c74-4b3a-b2d6-2b99523df41f",
   "metadata": {},
   "source": [
    "## losses.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5214eac-fc1f-4b75-a44b-712feb356aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        bce = F.binary_cross_entropy_with_logits(input, target)\n",
    "        smooth = 1e-5\n",
    "        input = torch.sigmoid(input)\n",
    "        num = target.size(0)\n",
    "        input = input.view(num, -1)\n",
    "        target = target.view(num, -1)\n",
    "        intersection = (input * target)\n",
    "        dice = (2. * intersection.sum(1) + smooth) / (input.sum(1) + target.sum(1) + smooth)\n",
    "        dice = 1 - dice.sum() / num\n",
    "        return 0.5 * bce + dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "840f65af-e16e-4ccc-af4a-b98330cd76b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from LovaszSoftmax.pytorch.lovasz_losses import lovasz_hinge\n",
    "# class LovaszHingeLoss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def forward(self, input, target):\n",
    "#         input = input.squeeze(1)\n",
    "#         target = target.squeeze(1)\n",
    "#         loss = lovasz_hinge(input, target, per_image=True)\n",
    "\n",
    "#         return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c82b1b6-3eb1-4f20-b01b-a0e675f611c4",
   "metadata": {},
   "source": [
    "## dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48c25584-f2c6-4f04-8ba6-a2e26c67cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_ids, img_dir, mask_dir, img_ext, mask_ext, num_classes, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_ids (list): Image ids.\n",
    "            img_dir: Image file directory.\n",
    "            mask_dir: Mask file directory.\n",
    "            img_ext (str): Image file extension.\n",
    "            mask_ext (str): Mask file extension.\n",
    "            num_classes (int): Number of classes.\n",
    "            transform (Compose, optional): Compose transforms of albumentations. Defaults to None.\n",
    "        \n",
    "        Note:\n",
    "            Make sure to put the files as the following structure:\n",
    "            <dataset name>\n",
    "            ├── images\n",
    "            |   ├── 0a7e06.jpg\n",
    "            │   ├── 0aab0a.jpg\n",
    "            │   ├── 0b1761.jpg\n",
    "            │   ├── ...\n",
    "            |\n",
    "            └── masks\n",
    "                ├── 0\n",
    "                |   ├── 0a7e06.png\n",
    "                |   ├── 0aab0a.png\n",
    "                |   ├── 0b1761.png\n",
    "                |   ├── ...\n",
    "                |\n",
    "                ├── 1\n",
    "                |   ├── 0a7e06.png\n",
    "                |   ├── 0aab0a.png\n",
    "                |   ├── 0b1761.png\n",
    "                |   ├── ...\n",
    "                ...\n",
    "        \"\"\"\n",
    "        self.img_ids = img_ids\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.img_ext = img_ext\n",
    "        self.mask_ext = mask_ext\n",
    "        self.num_classes = num_classes\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        \n",
    "        img = cv2.imread(os.path.join(self.img_dir, img_id + self.img_ext))\n",
    "\n",
    "        mask = []\n",
    "        for i in range(self.num_classes):\n",
    "            mask.append(cv2.imread(os.path.join(self.mask_dir, str(i),\n",
    "                        img_id + self.mask_ext), cv2.IMREAD_GRAYSCALE)[..., None])\n",
    "        mask = np.dstack(mask)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmented = self.transform(image=img, mask=mask)\n",
    "            img = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "        \n",
    "        img = img.astype('float32') / 255\n",
    "        img = img.transpose(2, 0, 1)\n",
    "        mask = mask.astype('float32') / 255\n",
    "        mask = mask.transpose(2, 0, 1)\n",
    "        \n",
    "        return img, mask, {'img_id': img_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde833ed-cffb-401e-aa94-aeaad09c08d1",
   "metadata": {},
   "source": [
    "## metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ce8e4b1-9a65-47b2-ae30-1bdea8abe6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_score(output, target):\n",
    "    smooth = 1e-5\n",
    "\n",
    "    if torch.is_tensor(output):\n",
    "        output = torch.sigmoid(output).data.cpu().numpy()\n",
    "    if torch.is_tensor(target):\n",
    "        target = target.data.cpu().numpy()\n",
    "    output_ = output > 0.5\n",
    "    target_ = target > 0.5\n",
    "    intersection = (output_ & target_).sum()\n",
    "    union = (output_ | target_).sum()\n",
    "\n",
    "    return (intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2063835f-fab6-4d29-9969-d555888f9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(output, target):\n",
    "    smooth = 1e-5\n",
    "\n",
    "    output = torch.sigmoid(output).view(-1).data.cpu().numpy()\n",
    "    target = target.view(-1).data.cpu().numpy()\n",
    "    intersection = (output * target).sum()\n",
    "\n",
    "    return (2. * intersection + smooth) / \\\n",
    "        (output.sum() + target.sum() + smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb098100-b4d7-43d5-9d85-943e04aeb9b8",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a6f36b5-5e8c-47d6-a8f8-83191996492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    if v.lower() in ['true', 1]:\n",
    "        return True\n",
    "    elif v.lower() in ['false', 0]:\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc16f96d-291b-44e1-a831-94b120a84213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b031ea6-3019-4f99-a3a5-fced639bf93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc21b013-aed1-4a89-8d39-3053ad51f87f",
   "metadata": {},
   "source": [
    "## python train.py --dataset dsb2018_96 --arch NestedUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb6b8f7-dad9-4b2e-9a42-03bf95101db9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
